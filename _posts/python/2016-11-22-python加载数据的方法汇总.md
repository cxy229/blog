---
layout     : post
title      : python加载数据的方法汇总
categories : [python]
tags       : [notes]
---

### 加载第三方的数据集

#### scikit-learn Toy数据集

```
from sklearn import datasets

iris = datasets.load_iris()
boston = datasets.load_boston()
digits = datasets.load_digits()

# 查看数据集信息
print (iris.DESCR)
print (iris.data)
print (iris.data.shape)
print (iris.feature_names)
print (iris.target)
print (iris.target.shape)
print (iris.target_names)
```

#### mldata.org公共资源库

```
from sklearn.datasets import fetch_mldata
earthquakes = fetch_mldata('global-earthquakes')
print (earthquakes.data.shape)
```

#### LIBSVM 

```
import urllib
target_page = 'http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary/a1a'
a2a = urllib.request.urlopen(target_page)
from sklearn.datasets import load_svmlight_file
X_train, y_train = load_svmlight_file(a2a)
print (X_train.shape, y_train.shape)
```

### 导入本地数据集

##### numpy.loadtxt
可用来加载单一类型数据集，用loadtxt命令可节省内存

```
import numpy as np
housing = np.loadtxt('regression-datasets-housing.csv',delimiter=',', dtype=int)  # 数据均为整型，分隔符是','
print (type(housing))
```
`<class 'numpy.ndarray'>`

##### pandas.read_csv

```
import pandas as pd
iris_filename = 'datasets-uci-iris.csv'
iris = pd.read_csv(iris_filename, sep=',', decimal='.',  \
header=None, names= ['sepal_length', 'sepal_width', 'petal_length', \
'petal_width', 'target'])
print (type(iris))
```
`<class 'pandas.core.frame.DataFrame'>`

##### DataFrame 转 Numpy数组

```
iris_data = iris.values[:,:4]
iris_target, iris_target_labels = pd.factorize(iris.target)
print (iris_data.shape, iris_target.shape)
```
`(150, 4) (150,)`

### 生成数据集

#### Scikit-learn 样本生成器

```
from sklearn import datasets # We just import the "datasets" module
X,y = datasets.make_classification(n_samples=10**6, \
n_features=10, random_state=101)
print (X.shape,  y.shape)
```
`(1000000, 10) (1000000,)`

```
datasets.make_classification(1, n_features=4, random_state=101)
```
`(array([[-3.31994186, -2.39469384, -2.35882002,  1.40145585]]), array([0]))`

- 赋给`random_state`一个确定的int值，就可以保证在不同的计算机上生成完全相同的数据集
